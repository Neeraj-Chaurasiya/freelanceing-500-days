# Web Scraping Notes

## 1Ô∏è‚É£ Libraries Install & Import

```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
```

* `requests` ‚Üí Fetch website HTML.
* `BeautifulSoup` ‚Üí Parse HTML and extract data.
* `pandas` ‚Üí Store data in DataFrame and save to CSV.

---

## 2Ô∏è‚É£ Simple Web Request

```python
url = "https://books.toscrape.com/"
response = requests.get(url)
print(response.status_code)
```

* `requests.get(url)` ‚Üí Get webpage content.
* `response.status_code` ‚Üí 200 = success, 404 = not found.

---

## 3Ô∏è‚É£ Parse HTML with BeautifulSoup

```python
soup = BeautifulSoup(response.text, "html.parser")
print(soup.title.text)
```

* `response.text` ‚Üí HTML content.
* `BeautifulSoup(..., "html.parser")` ‚Üí Parse HTML.
* `soup.title.text` ‚Üí Print page title.

---

## 4Ô∏è‚É£ Extract Multiple Elements

```python
books = soup.find_all("h3")
title = [book.a["title"] for book in books]
print(title)
```

* `find_all("h3")` ‚Üí Get all `<h3>` tags.
* `book.a["title"]` ‚Üí Get book title from anchor tag.
* List comprehension ‚Üí Create list of titles.

---

## 5Ô∏è‚É£ Store Data in DataFrame & CSV

```python
df = pd.DataFrame({"Books title ": title})
df.to_csv("Books.csv", index=False)
print("Saved to books.csv")
```

* `pd.DataFrame()` ‚Üí Convert list to table.
* `to_csv()` ‚Üí Save DataFrame to CSV.
* `index=False` ‚Üí Exclude row indices.

---

## 6Ô∏è‚É£ Practice Task üöÄ

```python
books = soup.find_all("article", class_="product_pod")
```

* Select each book block in the page.

```python
titles = []
prices = []
ratings = []
```

* Create empty lists for storing book data.

### Loop through each book:

```python
for book in books:
    title = book.h3.a["title"]
    titles.append(title)

    price = book.find("p", class_="price_color").text
    prices.append(price)

    rating = book.p["class"][1]
    ratings.append(rating)

    df = pd.DataFrame({
        "Title": titles,
        "Price": prices,
        "Rating": ratings
    })
```

* Extract `title`, `price`, `rating` for each book.
* Append to respective lists.
* Create/update DataFrame inside loop (for incremental view).

```python
df.to_csv("book_price.csv", index=False)
print("Data saved to book_price.csv")
```

* Save final DataFrame to CSV.
* `index=False` ‚Üí Exclude row numbers.

---

## 7Ô∏è‚É£ Summary

* **Requests** ‚Üí Get webpage HTML.
* **BeautifulSoup** ‚Üí Parse HTML, extract tags & attributes.
* **Data Extraction** ‚Üí Get book titles, prices, and ratings.
* **DataFrame & CSV** ‚Üí Store extracted data and save to file.
* **Key Functions**: `requests.get()`, `soup.find_all()`, `tag["attribute"]`, `.text`, `pd.DataFrame()`, `.to_csv()`.
